{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeabsiraNigusse/machine-Learning/blob/main/semantic_search/Q%26A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ca754e0",
      "metadata": {
        "id": "7ca754e0"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "3dac6c41",
      "metadata": {
        "id": "3dac6c41"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from chromadb.utils import embedding_functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2530d37a",
      "metadata": {
        "id": "2530d37a"
      },
      "outputs": [],
      "source": [
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "                api_key='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',\n",
        "                model_name=\"text-embedding-ada-002\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "67667623",
      "metadata": {
        "id": "67667623"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "client = chromadb.Client()\n",
        "\n",
        "collection = client.get_or_create_collection('demo', embedding_function=openai_ef)#collection is like database used to store documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "9a7e79d7",
      "metadata": {
        "id": "9a7e79d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa291d5e-bb2b-44af-a312-42ed4d5fb6e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: id1\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: id2\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: id1\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: id2\n"
          ]
        }
      ],
      "source": [
        "collection.add(\n",
        "    documents=['This a document about cat', 'This a document about a car'],\n",
        "    metadatas=[{'catagory': 'animal'}, {'catagory':'automobile'}],\n",
        "    ids=['id1', 'id2']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f69ee80d",
      "metadata": {
        "id": "f69ee80d",
        "outputId": "f1608cb5-7461-4082-c87e-3a1ebe319755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [['id2']],\n",
              " 'distances': [[0.3224184215068817]],\n",
              " 'metadatas': [[{'catagory': 'automobile'}]],\n",
              " 'embeddings': None,\n",
              " 'documents': [['This a document about a car']]}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "results = collection.query(\n",
        "    query_texts=['automobil'],\n",
        "    n_results=1\n",
        ")\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "47dae13a",
      "metadata": {
        "id": "47dae13a",
        "outputId": "466c05a7-efa5-4411-de8c-a452895039aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5161cbc0",
      "metadata": {
        "id": "5161cbc0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_files(folder_path):\n",
        "  file_data = []\n",
        "\n",
        "  for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith(\".txt\"):\n",
        "      with open(os.path.join(folder_path, file_name), 'r') as file:\n",
        "        content = file.read()\n",
        "        file_data.append({'file_name': file_name, 'content': content})\n",
        "\n",
        "  return file_data\n",
        "\n",
        "folder_path = 'drive/MyDrive/articles'\n",
        "\n",
        "datas = read_files(folder_path)\n",
        "for data in datas:\n",
        "  print(f\"file name: {data['file_name']}\")\n",
        "  print(f\"content: {data['content']}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "ac89c70e",
      "metadata": {
        "id": "ac89c70e",
        "outputId": "1eaec0b8-1442-45b8-9c47-d7caf3856307",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'source': 'numpy.txt'},\n",
              " {'source': 'pandas.txt'},\n",
              " {'source': 'scikit-learn.txt'},\n",
              " {'source': 'scipy.txt'},\n",
              " {'source': 'tesorflow vs pytorch.txt'},\n",
              " {'source': 'ben article.txt'}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "documents = []\n",
        "metadatas = []\n",
        "ids = []\n",
        "\n",
        "for index, data in enumerate(datas):\n",
        "  documents.append(data['content'])\n",
        "  metadatas.append({'source':data['file_name']})\n",
        "  ids.append(str(index+1))\n",
        "\n",
        "metadatas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "50ec7455",
      "metadata": {
        "id": "50ec7455"
      },
      "outputs": [],
      "source": [
        "client = chromadb.PersistentClient(path=\"database\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8dc99a3c",
      "metadata": {
        "id": "8dc99a3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e10242-cd07-4ce1-bbab-deeb69b14507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 1\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 3\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 4\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 5\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 1\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 3\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 4\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 5\n"
          ]
        }
      ],
      "source": [
        "lib_collection = client.get_or_create_collection('lib_collection',embedding_function=openai_ef)\n",
        "\n",
        "lib_collection.add(\n",
        "    documents=documents,\n",
        "    metadatas=metadatas,\n",
        "    ids=ids\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "f415908e",
      "metadata": {
        "id": "f415908e"
      },
      "outputs": [],
      "source": [
        "results = lib_collection.query(\n",
        "    query_texts=['select a document that talke about africa'],\n",
        "    n_results=2\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "6082128a",
      "metadata": {
        "id": "6082128a"
      },
      "outputs": [],
      "source": [
        "res = \"\\n\".join(str(item) for item in results['documents'])\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "prompt=f\"\"\"\n",
        "{res}\n",
        " \\n\\n Based on the above data,\n",
        "\n",
        "tell me the main ideas raised in the document?\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(prompt)"
      ],
      "metadata": {
        "id": "_XlQiWPs2HeD",
        "outputId": "3d35e78b-a7c6-4eb4-cd0d-49a80d32e573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "id": "_XlQiWPs2HeD",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The main ideas raised in the document are:\\n\\n1. The uneven distribution of technology in sub-Saharan Africa and its impact on the economy.\\n2. The potential of various technological applications to uplift Africa's economy, including credit scoring, supply chain management, smart power, educational software, and automated tools for health and agriculture.\\n3. The importance of speech-to-speech machine translation for under-resourced languages in Africa to overcome linguistic barriers and access knowledge.\\n4. The increasing mobile phone penetration and internet access in Africa, but the challenge of linguistic incompatibilities and illiteracy.\\n5. The advancements in speech-to-speech machine translation and the potential for training systems to translate African languages into other languages.\\n6. The need for funding and support to provide translation services to the African population.\\n7. The possibility of distributing processing power for machine translation through projects like GOLEM Network and NuNet.io.\\n8. The potential of advanced technologies to empower disenfranchised and impoverished people in Africa and integrate them into the global economy.\\n9. A comparison between TensorFlow and PyTorch as deep learning libraries, discussing their features, strengths, and weaknesses.\\n10. The dominance of TensorFlow in industry and its ability to handle large projects, while PyTorch is considered easier to learn and faster to implement.\\n11. The recommendation to choose TensorFlow for building production-ready deep learning models at scale, and PyTorch for rapid prototyping.\\n12. The availability of resources and courses to learn TensorFlow and PyTorch.\\n13. The importance of continuously learning and exploring different AI programming languages for specific tasks and industries.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JnCeKPZjdscy"
      },
      "id": "JnCeKPZjdscy",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_messages_with_owners = []\n",
        "\n",
        "# Open and read the chat.txt file\n",
        "with open('drive/MyDrive/chats/chat.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Initialize a variable to keep track of the current speaker\n",
        "current_speaker = None\n",
        "\n",
        "# Iterate through the lines and extract all messages with owners\n",
        "for line in lines:\n",
        "    if line.strip():  # Check if the line is not empty\n",
        "        parts = line.split(': ', 1)  # Split the line into speaker and message\n",
        "        if len(parts) == 2:  # Ensure there is a speaker and a message\n",
        "            speaker, message = parts[0], parts[1].strip()\n",
        "            if current_speaker != speaker:\n",
        "                current_speaker = speaker\n",
        "                all_messages_with_owners.append(f\"{current_speaker}: {message}\")\n",
        "            else:\n",
        "                all_messages_with_owners[-1] += f\"\\n{message}\""
      ],
      "metadata": {
        "id": "64w9qedVOAfA"
      },
      "id": "64w9qedVOAfA",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_messages_with_owners"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEm9i23oOTOF",
        "outputId": "274ab3f5-df44-4bd6-e494-b67257f6a535"
      },
      "id": "uEm9i23oOTOF",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['janet: I am very happy to say that after many months of wanting to spend time working on bringing @benâ€™s vision of speech to speech machine translation in Africa to life, we now have a little bit of capacity and some strong new connections with which to take this forward.',\n",
              " 'Ben: Great to see the movement here!',\n",
              " 'janet: Yes!! Tee came out with us in London on wednesday as well, really glad to work with him\\nAs we have an open partnership discussion with Baaba for Jam Galaxy there is always some chance he will help us a little with the project somehow and his NGO NANN-K',\n",
              " 'hruy: Great initiative with a super cool and novel objective. It can also expand to South America and parts of Asia where there is a similar problem related to languages dying and languages lacking a writing system.',\n",
              " \"Most of the cross-country languages like Swahili have adopted a writing system, in this case, Arabic, and the major languages usually adopt the Western alphabet. Ethiopia is the only African country with it's own writing system. Another thing is most of Africa is divided mainly into three groups: English-speaking, French-speaking, and Arabic-speaking.\",\n",
              " 'janet: Thank you so much @Hruy Tsegaye for your insights and support!',\n",
              " 'surgey: Hi, I suppose starting collecting/scraping/filtering speech datasets - all we could get might be a great task for Ethiopean team, it usually takes lots of time in fact, we could also delegate one of the most experienced data engineer from Russian team to master the process.',\n",
              " 'janet: Thanks @sergeyshalyapin did you put this in your planned allocations shared with Jan and Rachel and if not can you please add it?']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=f\"\"\"\n",
        "\n",
        "\n",
        "  You are a helpful assistant, you always only answer for the assistant then you stop. You will only answer the question the Human asks.\n",
        "  You will be given a list that contain chats related to a certain topic whis is found in the following list\n",
        "\n",
        "  {all_messages_with_owners}\n",
        "\n",
        "  Write a response that answers the question based on what is discussed in the above list.\n",
        "  You must answer the question based on only the list of chats you are given.\n",
        "  Don't answer anything outside the context you are provided and do not respond with anything from your general knowledge.\n",
        "  Try to mention the ones that you get the context from.\n",
        "  You may also look at the chat history to get additional context if necessary.\n",
        "  If there isn't enough context, simply reply \"This topic was not discussed previously\"\n",
        "\n",
        "what is coffee?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Pgx9Zr2yPGBF"
      },
      "id": "Pgx9Zr2yPGBF",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iWfHcCCuPNcQ",
        "outputId": "bd6f56df-facf-4322-a027-9ca9c89be005"
      },
      "id": "iWfHcCCuPNcQ",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This topic was not discussed previously.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=f\"\"\"\n",
        "\n",
        "\n",
        "  You are a helpful assistant, you always only answer for the assistant then you stop. You will only answer the question the Human asks.\n",
        "  You will be given a list that contain chats related to a certain topic whis is found in the following list\n",
        "\n",
        "  {all_messages_with_owners}\n",
        "\n",
        "  Write a response that answers the question based on what is discussed in the above list.\n",
        "  You must answer the question based on only the list of chats you are given.\n",
        "  Don't answer anything outside the context you are provided and do not respond with anything from your general knowledge.\n",
        "  Try to mention the ones that you get the context from.\n",
        "  You may also look at the chat history to get additional context if necessary.\n",
        "  If there isn't enough context, simply reply \"This topic was not discussed previously\"\n",
        "\n",
        "what is Machine Learning?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "j627pWfsPV6o"
      },
      "id": "j627pWfsPV6o",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fLVphqCGPYRv",
        "outputId": "8b9aba96-4820-4456-879f-ff14a74c8f15"
      },
      "id": "fLVphqCGPYRv",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This topic was not discussed previously.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=f\"\"\"\n",
        "\n",
        "\n",
        "  You are a helpful assistant, you always only answer for the assistant then you stop. You will only answer the question the Human asks.\n",
        "  You will be given a list that contain chats related to a certain topic whis is found in the following list\n",
        "\n",
        "  {all_messages_with_owners}\n",
        "\n",
        "  Write a response that answers the question based on what is discussed in the above list.\n",
        "  You must answer the question based on only the list of chats you are given.\n",
        "  Don't answer anything outside the context you are provided.\n",
        "  Only answer questions if the direct answer exists in the list of chats!\n",
        "  If there isn't enough context, simply reply \"This topic was not discussed previously\"\n",
        "\n",
        "what is the project about they are talking about? explain me in detail?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "g4qhLUJrPd7m"
      },
      "id": "g4qhLUJrPd7m",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "9nHMbkBUPizD",
        "outputId": "817ca6b6-324f-4205-94ad-3a910899b2d3"
      },
      "id": "9nHMbkBUPizD",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The project they are talking about is focused on bringing Ben's vision of speech to speech machine translation to life in Africa. They mention having some capacity and strong new connections to move the project forward. Additionally, they discuss the possibility of partnering with Baaba for Jam Galaxy and his NGO NANN-K. The project aims to address the problem of languages dying and lacking a writing system in Africa, with a focus on expanding to South America and parts of Asia as well.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}