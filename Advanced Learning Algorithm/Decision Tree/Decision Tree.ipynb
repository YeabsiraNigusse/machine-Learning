{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/Decision%20Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BGhgTGlrKJ9O",
      "metadata": {
        "id": "BGhgTGlrKJ9O"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0tjka-dNKY5f",
      "metadata": {
        "id": "0tjka-dNKY5f"
      },
      "source": [
        "In this notebook we will see\n",
        "- what decision tree is\n",
        "- what entropy is and how it is calcuated\n",
        "- what information gain is and how we can caluculate it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quNE29iVK_7I",
      "metadata": {
        "id": "quNE29iVK_7I"
      },
      "source": [
        "A decision tree is a type of supervised machine learning used to categorize or make predictions based on how a previous set of questions were answered. The model is a form of supervised learning, meaning that the model is trained and tested on a set of data that contains the desired categorization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3_uz3ka-LQeF",
      "metadata": {
        "id": "3_uz3ka-LQeF"
      },
      "source": [
        "In the context of Decision Trees, entropy is a measure of disorder or impurity in a node. Thus, a node with more variable composition, such as 2Pass and 2 Fail would be considered to have higher Entropy than a node which has only pass or only fail."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RnXahwX0LnES",
      "metadata": {
        "id": "RnXahwX0LnES"
      },
      "source": [
        "The entropy, defined as\n",
        "\n",
        "$$H(p_1) = -p_1 \\text{log}_2(p_1) - (1- p_1) \\text{log}_2(1- p_1)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Q91n8LcdLPKv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q91n8LcdLPKv",
        "outputId": "d884db1d-1ec2-4cbe-a3c4-84f54be01ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "wyvLFeKkMKWO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "wyvLFeKkMKWO",
        "outputId": "f1ab6bde-be3d-4878-e993-879edfa3f326"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0480f09a-b7c8-4125-a83d-eaf70068b97a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0480f09a-b7c8-4125-a83d-eaf70068b97a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving deeplearning.mplstyle to deeplearning (1).mplstyle\n",
            "Saving utils.py to utils (1).py\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3w7OdxZCKOg3",
      "metadata": {
        "id": "3w7OdxZCKOg3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74aMC3BoNNG8",
      "metadata": {
        "id": "74aMC3BoNNG8"
      },
      "source": [
        "|                                                     |   Ear Shape | Face Shape | Whiskers |   Cat  |\n",
        "|:---------------------------------------------------:|:---------:|:-----------:|:---------:|:------:|\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/0.png?raw=1\" alt=\"drawing\" width=\"50\"/> |   Pointy   |   Round     |  Present  |    1   |\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/1.png?raw=1\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Not Round  |  Present  |    1   |\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/2.png?raw=1\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Round      |  Absent   |    0   |\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/3.png?raw=1\" alt=\"drawing\" width=\"50\"/> |   Pointy   |  Not Round  |  Present  |    0   |\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/4.png?raw=1\" alt=\"drawing\" width=\"50\"/> |   Pointy   |   Round     |  Present  |    1   |\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/5.png?raw=1\" alt=\"drawing\" width=\"50\"/> |   Pointy   |   Round     |  Absent   |    1   |\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/6.png?raw=1\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Not Round  |  Absent   |    0   |\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/7.png?raw=1\" alt=\"drawing\" width=\"50\"/> |   Pointy   |  Round      |  Absent   |    1   |\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/8.png?raw=1\" alt=\"drawing\" width=\"50\"/> |    Floppy  |   Round     |  Absent   |    0   |\n",
        "| <img src=\"https://github.com/YeabsiraNigusse/machine-Learning/blob/main/Decision%20Tree/images/9.png?raw=1\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Round      |  Absent   |    0   |\n",
        "\n",
        "\n",
        "We will use **one-hot encoding** to encode the categorical features. They will be as follows:\n",
        "\n",
        "- Ear Shape: Pointy = 1, Floppy = 0\n",
        "- Face Shape: Round = 1, Not Round = 0\n",
        "- Whiskers: Present = 1, Absent = 0\n",
        "\n",
        "Therefore, we have two sets:\n",
        "\n",
        "- `X_train`: for each example, contains 3 features:\n",
        "            - Ear Shape (1 if pointy, 0 otherwise)\n",
        "            - Face Shape (1 if round, 0 otherwise)\n",
        "            - Whiskers (1 if present, 0 otherwise)\n",
        "            \n",
        "- `y_train`: whether the animal is a cat\n",
        "            - 1 if the animal is a cat\n",
        "            - 0 otherwise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-2sS5wfOOCWf",
      "metadata": {
        "id": "-2sS5wfOOCWf"
      },
      "source": [
        "The data set as a collection of array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "YfuipaHlM6m4",
      "metadata": {
        "id": "YfuipaHlM6m4"
      },
      "outputs": [],
      "source": [
        "X_train = np.array([[1, 1, 1],\n",
        "[0, 0, 1],\n",
        " [0, 1, 0],\n",
        " [1, 0, 1],\n",
        " [1, 1, 1],\n",
        " [1, 1, 0],\n",
        " [0, 0, 0],\n",
        " [1, 1, 0],\n",
        " [0, 1, 0],\n",
        " [0, 1, 0]])\n",
        "\n",
        "y_train = np.array([1, 1, 0, 0, 1, 1, 0, 1, 0, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gOQgtGAQOKHe",
      "metadata": {
        "id": "gOQgtGAQOKHe"
      },
      "source": [
        "### Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "CY3_QqpQNX7s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY3_QqpQNX7s",
        "outputId": "896cbf01-195b-4c0a-b3ba-fc9acfd92374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "def entropy(p):\n",
        "    if p == 0 or p == 1:\n",
        "        return 0\n",
        "    else:\n",
        "        return -p * np.log2(p) - (1- p)*np.log2(1 - p)\n",
        "\n",
        "print(entropy(0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8QeEWD1DOPe5",
      "metadata": {
        "id": "8QeEWD1DOPe5"
      },
      "source": [
        "The function help us to separate the data set based on its feature\n",
        "\n",
        "e.g for ears it might be pointy or floppy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7wPjvMt8NePv",
      "metadata": {
        "id": "7wPjvMt8NePv"
      },
      "outputs": [],
      "source": [
        "def split_indices(X, index_feature):\n",
        "    \"\"\"Given a dataset and a index feature, return two lists for the two split nodes, the left node has the animals that have\n",
        "    that feature = 1 and the right node those that have the feature = 0\n",
        "    index feature = 0 => ear shape\n",
        "    index feature = 1 => face shape\n",
        "    index feature = 2 => whiskers\n",
        "    \"\"\"\n",
        "    left_indices = []\n",
        "    right_indices = []\n",
        "    for i,x in enumerate(X):\n",
        "        if x[index_feature] == 1:\n",
        "            left_indices.append(i)\n",
        "        else:\n",
        "            right_indices.append(i)\n",
        "    return left_indices, right_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ymyiwOibOh9K",
      "metadata": {
        "id": "ymyiwOibOh9K"
      },
      "source": [
        "we calculate the two catagory entropy to test how match the feature perform well from other similar features. we take the average of both its left and right by considering their weight(total number of the catagory/ total dataset) and calculatating entropy for each `trget value` it might be cat or dog in our example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "tcjlEG8BNjpF",
      "metadata": {
        "id": "tcjlEG8BNjpF"
      },
      "outputs": [],
      "source": [
        "def weighted_entropy(X,y,left_indices,right_indices):\n",
        "    \"\"\"\n",
        "    This function takes the splitted dataset, the indices we choose to split and returns the weighted entropy.\n",
        "    \"\"\"\n",
        "    w_left = len(left_indices)/len(X)\n",
        "    w_right = len(right_indices)/len(X)\n",
        "    p_left = sum(y[left_indices])/len(left_indices)\n",
        "    p_right = sum(y[right_indices])/len(right_indices)\n",
        "\n",
        "    weighted_entropy = w_left * entropy(p_left) + w_right * entropy(p_right)\n",
        "    return weighted_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "hK1pBMTiNq-z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK1pBMTiNq-z",
        "outputId": "195fa67d-d1ae-435b-c321-c0c110aca647"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7219280948873623"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "left_indices, right_indices = split_indices(X_train, 0)\n",
        "weighted_entropy(X_train, y_train, left_indices, right_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IyNNV0XoPl4k",
      "metadata": {
        "id": "IyNNV0XoPl4k"
      },
      "source": [
        "### Information Gain\n",
        "\n",
        "the main thing to distingushe the performance of each feature in our dataset is by using entropy however the exact value we use to decide that which feature perform well is called `information Gain`\n",
        "\n",
        "it is defined as\n",
        "$$\\text{Information Gain} = H(p_1^\\text{node})- \\left(w^{\\text{left}}H\\left(p_1^\\text{left}\\right) + w^{\\text{right}}H\\left(p_1^\\text{right}\\right)\\right),$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "TNPSFviANuwE",
      "metadata": {
        "id": "TNPSFviANuwE"
      },
      "outputs": [],
      "source": [
        "def information_gain(X, y, left_indices, right_indices):\n",
        "    \"\"\"\n",
        "    Here, X has the elements in the node and y is theirs respectives classes\n",
        "    \"\"\"\n",
        "    p_node = sum(y)/len(y)\n",
        "    h_node = entropy(p_node)\n",
        "    w_entropy = weighted_entropy(X,y,left_indices,right_indices)\n",
        "    return h_node - w_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "kfL_Pq2wN1u9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfL_Pq2wN1u9",
        "outputId": "0fa88973-35ed-4959-a35f-769695d6997a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2780719051126377"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "information_gain(X_train, y_train, left_indices, right_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qOmIx_3MQykV",
      "metadata": {
        "id": "qOmIx_3MQykV"
      },
      "source": [
        "#### We can calculate the `information gain` for each feature and see how each feature well in reducing entropy on the classification problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "hC6b2OMXN5WN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC6b2OMXN5WN",
        "outputId": "16d79a41-43bb-426c-f434-f7617608da5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature: Ear Shape, information gain if we split the root node using this feature: 0.28\n",
            "Feature: Face Shape, information gain if we split the root node using this feature: 0.03\n",
            "Feature: Whiskers, information gain if we split the root node using this feature: 0.12\n"
          ]
        }
      ],
      "source": [
        "for i, feature_name in enumerate(['Ear Shape', 'Face Shape', 'Whiskers']):\n",
        "    left_indices, right_indices = split_indices(X_train, i)\n",
        "    i_gain = information_gain(X_train, y_train, left_indices, right_indices)\n",
        "    print(f\"Feature: {feature_name}, information gain if we split the root node using this feature: {i_gain:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YYtX9s3EN-nb",
      "metadata": {
        "id": "YYtX9s3EN-nb"
      },
      "source": [
        "The process is **recursive**, which means we must perform these calculations for each node until we meet a stopping criteria:\n",
        "\n",
        "- If the tree depth after splitting exceeds a threshold\n",
        "- If the resulting node has only 1 class\n",
        "- If the information gain of splitting is below a threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cLfdgQOZN_T3",
      "metadata": {
        "id": "cLfdgQOZN_T3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
