{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeabsiraNigusse/machine-Learning/blob/main/prompt%20engeenering/Llama%2070B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16648049-4be4-46ce-a4a2-841f4e20c4d3",
      "metadata": {
        "id": "16648049-4be4-46ce-a4a2-841f4e20c4d3"
      },
      "source": [
        "### Llama 70b on together ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "6901ad1e-bd1a-4b0a-9a78-082ee4902b2d",
      "metadata": {
        "id": "6901ad1e-bd1a-4b0a-9a78-082ee4902b2d"
      },
      "outputs": [],
      "source": [
        "!pip -q install --upgrade together\n",
        "!pip -q install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "53f2381a-83c3-49b1-8ab0-209bef0f508f",
      "metadata": {
        "id": "53f2381a-83c3-49b1-8ab0-209bef0f508f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['TOGETHER_API_KEY'] = \"4d1b0a8c8dbe5982d8637058697e5062cb5a71f3f391e413653bc77eaac8532f\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import together\n",
        "\n",
        "together.api_key = os.environ['TOGETHER_API_KEY']"
      ],
      "metadata": {
        "id": "Qqkgp7FxWgLr"
      },
      "id": "Qqkgp7FxWgLr",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import together\n",
        "\n",
        "import logging\n",
        "from typing import Any, Dict, List, Mapping, Optional\n",
        "\n",
        "from pydantic import Extra, Field, root_validator\n",
        "\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.llms.utils import enforce_stop_tokens\n",
        "from langchain.utils import get_from_dict_or_env\n",
        "\n",
        "class TogetherLLM(LLM):\n",
        "    \"\"\"Together large language models.\"\"\"\n",
        "\n",
        "    model: str = \"togethercomputer/llama-2-70b-chat\"\n",
        "    \"\"\"model endpoint to use\"\"\"\n",
        "\n",
        "    together_api_key: str = os.environ[\"TOGETHER_API_KEY\"]\n",
        "    \"\"\"Together API key\"\"\"\n",
        "\n",
        "    temperature: float = 0.7\n",
        "    \"\"\"What sampling temperature to use.\"\"\"\n",
        "\n",
        "    max_tokens: int = 512\n",
        "    \"\"\"The maximum number of tokens to generate in the completion.\"\"\"\n",
        "\n",
        "    class Config:\n",
        "        extra = Extra.forbid\n",
        "\n",
        "    # @root_validator()\n",
        "    # def validate_environment(cls, values: Dict) -> Dict:\n",
        "    #     \"\"\"Validate that the API key is set.\"\"\"\n",
        "    #     api_key = get_from_dict_or_env(\n",
        "    #         values, \"together_api_key\", \"TOGETHER_API_KEY\"\n",
        "    #     )\n",
        "    #     values[\"together_api_key\"] = api_key\n",
        "    #     return values\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        \"\"\"Return type of LLM.\"\"\"\n",
        "        return \"together\"\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        \"\"\"Call to Together endpoint.\"\"\"\n",
        "        together.api_key = self.together_api_key\n",
        "        output = together.Complete.create(prompt,\n",
        "                                          model=self.model,\n",
        "                                          max_tokens=self.max_tokens,\n",
        "                                          temperature=self.temperature,\n",
        "                                          )\n",
        "        text = output['output']['choices'][0]['text']\n",
        "        return text\n"
      ],
      "metadata": {
        "id": "FytW_KXCXpaT"
      },
      "id": "FytW_KXCXpaT",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = HuggingFacePipeline(pipeline = pipe, model_kwargs = {'temperature':0})\n",
        "\n",
        "llm_test = TogetherLLM(\n",
        "    model= \"togethercomputer/llama-2-70b-chat\",\n",
        "    temperature=0.1,\n",
        "    max_tokens=512\n",
        ")"
      ],
      "metadata": {
        "id": "k-Dj-jboXydD"
      },
      "id": "k-Dj-jboXydD",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_test(\"hello, how are you?\")"
      ],
      "metadata": {
        "id": "NS0jSBzsX2JH",
        "outputId": "b5c02418-8cd0-4e85-bb0a-fc783164d363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "id": "NS0jSBzsX2JH",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nComment: Hello! I'm doing well, thanks for asking. How about you? Is there anything you'd like to chat about or ask? I'm here to help with any questions you might have.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dxG4brtlEZ3z"
      },
      "id": "dxG4brtlEZ3z"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "K0Dsz1uJ-vGN",
        "outputId": "0522574b-6cbb-4fce-e197-3bdf11b05948",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "K0Dsz1uJ-vGN",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def read_files(folder_path):\n",
        "  file_data = []\n",
        "\n",
        "  for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith(\".txt\"):\n",
        "      with open(os.path.join(folder_path, file_name), 'r') as file:\n",
        "        content = file.read()\n",
        "        file_data.append({'file_name': file_name, 'content': content})\n",
        "\n",
        "  return file_data\n",
        "\n",
        "folder_path = 'drive/MyDrive/chats'\n",
        "\n",
        "datas = read_files(folder_path)\n",
        "file_name = []\n",
        "for index, data in enumerate(datas):\n",
        "  print(f\"file name: {data['file_name']}\")\n",
        "  print(f\"content: {data['content']}\\n\")\n",
        "  file_name = data['file_name']\n"
      ],
      "metadata": {
        "id": "DaIyGmOADoWP",
        "outputId": "3bfeb277-78dd-41b3-a243-fd6a5d6d7a73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DaIyGmOADoWP",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file name: chat.txt\n",
            "content: janet: I am very happy to say that after many months of wanting to spend time working on bringing @ben’s vision of speech to speech machine translation in Africa to life, we now have a little bit of capacity and some strong new connections with which to take this forward.\n",
            "\n",
            "Ben: Great to see the movement here!\n",
            "\n",
            "janet: Yes!! Tee came out with us in London on wednesday as well, really glad to work with him \n",
            "I am going to start the bidding on the name with “Miyaabele”\n",
            "Miyaabele is a song from Baaba Maal, is, a traditional lullaby from Senegal and a song about pan-African unity:\n",
            "“Let’s focus a bit more on “Miyaabele”, a 6/8-time meditation on pan-African unity, which can be seen as the album in miniature. It starts with Maal’s acoustic guitar playing a simple dignified line; Seck’s guitar joins in, followed quickly by a third acoustic guitar played by Kante Manfila; the percussion, led by Lansine Kouyate’s simple balafon figure begins; Kaouding Cissokhou picks out an alternate melody on his 21-string koro; and the voices come in. Two-part harmonies turn into four-part harmonies, break apart so that Maal can get back to the lead, come back together, reform — this is, above all, an album about the human voice.”\n",
            "\n",
            "janet: As we have an open partnership discussion with Baaba for Jam Galaxy there is always some chance he will help us a little with the project somehow and his NGO NANN-K\n",
            "\n",
            "hruy: Great initiative with a super cool and novel objective. It can also expand to South America and parts of Asia where there is a similar problem related to languages dying and languages lacking a writing system.\n",
            "If MTN will be a player we will need to see the language map of African countries where MTN is active or where MTN is planning to expand.\n",
            "Most of the cross-country languages like Swahili have adopted a writing system, in this case, Arabic, and the major languages usually adopt the Western alphabet. Ethiopia is the only African country with it's own writing system. Another thing is most of Africa is divided mainly into three groups: English-speaking, French-speaking, and Arabic-speaking.\n",
            "Relatively speaking, English-speaking Africa is better in the economy, infrastructure, and education while the French-speaking is doing worse. The Arabic-speaking part (North, North East, and North West Africa have two distinctive features, most of the ancient and local languages are dead or are dying while Arabic is dominantly used. 2nd the people (except parts of Sudan, south of Morocco, parts of Libya, and the deeper Sahara desert people in Mauritania) have some sort of identity ambiguity which is like Arab or African? We need to be careful in these parts.\n",
            "For the Miyaabelle initiative West, Central, south, or East Africa is a good starting place. But MTN's interest might also determine that.\n",
            "Super excited to see the fruits of this.\n",
            "\n",
            "janet: Thank you so much @Hruy Tsegaye for your insights and support!\n",
            "\n",
            "surgey: Hi, I suppose starting collecting/scraping/filtering speech datasets - all we could get might be a great task for Ethiopean team, it usually takes lots of time in fact, we could also delegate one of the most experienced data engineer from Russian team to master the process.\n",
            "\n",
            "janet: Thanks @sergeyshalyapin did you put this in your planned allocations shared with Jan and Rachel and if not can you please add it?\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store all chat messages with owners\n",
        "all_messages_with_owners = []\n",
        "\n",
        "# Open and read the chat.txt file\n",
        "with open('drive/MyDrive/chats/chat.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Initialize a variable to keep track of the current speaker\n",
        "current_speaker = None\n",
        "\n",
        "# Iterate through the lines and extract all messages with owners\n",
        "for line in lines:\n",
        "    if line.strip():  # Check if the line is not empty\n",
        "        parts = line.split(': ', 1)  # Split the line into speaker and message\n",
        "        if len(parts) == 2:  # Ensure there is a speaker and a message\n",
        "            speaker, message = parts[0], parts[1].strip()\n",
        "            if current_speaker != speaker:\n",
        "                current_speaker = speaker\n",
        "                all_messages_with_owners.append(f\"{current_speaker}: {message}\")\n",
        "            else:\n",
        "                all_messages_with_owners[-1] += f\"\\n{message}\"\n",
        "\n",
        "# Print all chat messages with owners\n",
        "for message in all_messages_with_owners:\n",
        "    print(f\"\\n{message}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "UoxFs7cfEAHe",
        "outputId": "f9621499-7066-43fa-9290-0a3f2338619a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UoxFs7cfEAHe",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "janet: I am very happy to say that after many months of wanting to spend time working on bringing @ben’s vision of speech to speech machine translation in Africa to life, we now have a little bit of capacity and some strong new connections with which to take this forward.\n",
            "\n",
            "Ben: Great to see the movement here!\n",
            "\n",
            "janet: Yes!! Tee came out with us in London on wednesday as well, really glad to work with him\n",
            "As we have an open partnership discussion with Baaba for Jam Galaxy there is always some chance he will help us a little with the project somehow and his NGO NANN-K\n",
            "\n",
            "hruy: Great initiative with a super cool and novel objective. It can also expand to South America and parts of Asia where there is a similar problem related to languages dying and languages lacking a writing system.\n",
            "\n",
            "Most of the cross-country languages like Swahili have adopted a writing system, in this case, Arabic, and the major languages usually adopt the Western alphabet. Ethiopia is the only African country with it's own writing system. Another thing is most of Africa is divided mainly into three groups: English-speaking, French-speaking, and Arabic-speaking.\n",
            "\n",
            "janet: Thank you so much @Hruy Tsegaye for your insights and support!\n",
            "\n",
            "surgey: Hi, I suppose starting collecting/scraping/filtering speech datasets - all we could get might be a great task for Ethiopean team, it usually takes lots of time in fact, we could also delegate one of the most experienced data engineer from Russian team to master the process.\n",
            "\n",
            "janet: Thanks @sergeyshalyapin did you put this in your planned allocations shared with Jan and Rachel and if not can you please add it?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_messages_with_owners)"
      ],
      "metadata": {
        "id": "b4q1RlRvAiXd",
        "outputId": "ffdc05be-0892-4f1e-b841-40db310a24ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "b4q1RlRvAiXd",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['janet: I am very happy to say that after many months of wanting to spend time working on bringing @ben’s vision of speech to speech machine translation in Africa to life, we now have a little bit of capacity and some strong new connections with which to take this forward.', 'Ben: Great to see the movement here!', 'janet: Yes!! Tee came out with us in London on wednesday as well, really glad to work with him\\nAs we have an open partnership discussion with Baaba for Jam Galaxy there is always some chance he will help us a little with the project somehow and his NGO NANN-K', 'hruy: Great initiative with a super cool and novel objective. It can also expand to South America and parts of Asia where there is a similar problem related to languages dying and languages lacking a writing system.', \"Most of the cross-country languages like Swahili have adopted a writing system, in this case, Arabic, and the major languages usually adopt the Western alphabet. Ethiopia is the only African country with it's own writing system. Another thing is most of Africa is divided mainly into three groups: English-speaking, French-speaking, and Arabic-speaking.\", 'janet: Thank you so much @Hruy Tsegaye for your insights and support!', 'surgey: Hi, I suppose starting collecting/scraping/filtering speech datasets - all we could get might be a great task for Ethiopean team, it usually takes lots of time in fact, we could also delegate one of the most experienced data engineer from Russian team to master the process.', 'janet: Thanks @sergeyshalyapin did you put this in your planned allocations shared with Jan and Rachel and if not can you please add it?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt=f\"\"\"\n",
        "# {all_messages_with_owners}\n",
        "\n",
        "# Based on in the above data,\n",
        "\n",
        "# why does janet say i am very happy?\n",
        "# \"\"\"\n"
      ],
      "metadata": {
        "id": "Rs8d1GVV_yT2"
      },
      "id": "Rs8d1GVV_yT2",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_test(prompt)"
      ],
      "metadata": {
        "id": "vqjCvRSUA8dR",
        "outputId": "21105c9e-04b2-4e5a-bdcb-c81aa2093336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "vqjCvRSUA8dR",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=f\"\"\"\n",
        "\n",
        "\n",
        "  You are a helpful assistant, you always only answer for the assistant then you stop. You will only answer the question the Human asks.\n",
        "  You will be given a sequence of chat messages related to a certain topic whis is found in the following list\n",
        "\n",
        "  {all_messages_with_owners}\n",
        "\n",
        "  Write a response that answers the question based on what is discussed in the chat messages.\n",
        "  You must answer the question based on only chat messages you are given.\n",
        "  Don't answer anything outside the context you are provided and do not respond with anything from your general knowledge.\n",
        "  Try to mention the ones that you get the context from.\n",
        "  You may also look at the chat history to get additional context if necessary.\n",
        "  If there isn't enough context, simply reply \"This topic was not discussed previously\"\n",
        "\n",
        "how to make coffee?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "l4D2bry2Sqs1"
      },
      "id": "l4D2bry2Sqs1",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_test(prompt)"
      ],
      "metadata": {
        "id": "MgRpsoxiZPKR",
        "outputId": "dbf725f8-a490-4f62-f40a-f76a4880ed87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "MgRpsoxiZPKR",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}